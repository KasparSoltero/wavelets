# core.py

from calendar import c
from json.encoder import INFINITY
from math import sqrt, floor, ceil, copysign, log, log2
import numpy as np
from matplotlib import pyplot as plt
from scipy.io import wavfile
import scipy.signal
from copy import copy

from hurst import compute_Hc
from scipy.stats import entropy as scientropy

##
## wavelet transform
##

def getCoefficients(mother_wavelet):
    # getCoefficients manually retrieves the scaling filter coefficients 
    # for the chosen mother wavelet. These coefficients can be found at:
    # http://wavelets.pybytes.com/wavelet/db1/

    match(mother_wavelet):
        case 'haar'|'db1'|'daubechies 1':
            coefficients = np.array([1/sqrt(2),1/sqrt(2)])
        case 'daubechies 2'|'db2':
            coefficients = np.array([0.48296291314469025,0.836516303737469,0.22414386804185735,-0.12940952255092145])
        case 'daubechies 3'|'db3':
            coefficients = np.array([0.035226291882100656,-0.08544127388224149,-0.13501102001039084,0.4598775021193313,0.8068915093133388,0.3326705529509569])
        case 'daubechies 4'|'db4':
            coefficients = np.array([-0.010597401784997278,0.032883011666982945,0.030841381835986965,-0.18703481171888114,-0.02798376941698385,0.6308807679295904,0.7148465705525415,0.23037781330885523])
        case 'db5':
            coefficients = np.array([0.003335725285001549,-0.012580751999015526,-0.006241490213011705,0.07757149384006515,-0.03224486958502952,-0.24229488706619015,0.13842814590110342,0.7243085284385744,0.6038292697974729,0.160102397974125])
        case 'db6':
            coefficients = np.array([-0.00107730108499558,0.004777257511010651,0.0005538422009938016,-0.031582039318031156,0.02752286553001629,0.09750160558707936,-0.12976686756709563,-0.22626469396516913,0.3152503517092432,0.7511339080215775,0.4946238903983854,0.11154074335008017])
        case 'db7':
            coefficients = np.array([0.0003537138000010399,-0.0018016407039998328,0.00042957797300470274,0.012550998556013784,-0.01657454163101562,-0.03802993693503463,0.0806126091510659,0.07130921926705004,-0.22403618499416572,-0.14390600392910627,0.4697822874053586,0.7291320908465551,0.39653931948230575,0.07785205408506236])
        case 'db8':
            coefficients = np.array([-0.00011747678400228192,0.0006754494059985568,-0.0003917403729959771,-0.00487035299301066,0.008746094047015655,0.013981027917015516,-0.04408825393106472,-0.01736930100202211,0.128747426620186,0.00047248457399797254,-0.2840155429624281,-0.015829105256023893,0.5853546836548691,0.6756307362980128,0.3128715909144659,0.05441584224308161])
        case 'db9':
            coefficients = np.array([3.9347319995026124e-05,-0.0002519631889981789,0.00023038576399541288,0.0018476468829611268,-0.004281503681904723,-0.004723204757894831,0.022361662123515244,0.00025094711499193845,-0.06763282905952399,0.030725681478322865,0.14854074933476008,-0.09684078322087904,-0.29327378327258685,0.13319738582208895,0.6572880780366389,0.6048231236767786,0.24383467463766728,0.03807794736316728])
        case 'db10':
            coefficients = np.array([-1.326420300235487e-05,9.358867000108985e-05,-0.0001164668549943862,-0.0006858566950046825,0.00199240529499085,0.0013953517469940798,-0.010733175482979604,0.0036065535669883944,0.03321267405893324,-0.02945753682194567,-0.07139414716586077,0.09305736460380659,0.12736934033574265,-0.19594627437659665,-0.24984642432648865,0.2811723436604265,0.6884590394525921,0.5272011889309198,0.18817680007762133,0.026670057900950818])
        case 'db11':
            coefficients = np.array([4.494274277236352e-06,-3.463498418698379e-05,5.443907469936638e-05,0.00024915252355281426,-0.0008930232506662366,-0.00030859285881515924,0.004928417656058778,-0.0033408588730145018,-0.015364820906201324,0.02084090436018004,0.03133509021904531,-0.06643878569502022,-0.04647995511667613,0.14981201246638268,0.06604358819669089,-0.27423084681792875,-0.16227524502747828,0.41196436894789695,0.6856867749161785,0.44989976435603013,0.1440670211506196,0.01869429776147044])
        case 'db12':
            coefficients = np.array([-1.5290717580684923e-06,1.2776952219379579e-05,-2.4241545757030318e-05,-8.850410920820318e-05,0.0003886530628209267,6.5451282125215034e-06,-0.0021795036186277044,0.0022486072409952287,0.006711499008795549,-0.012840825198299882,-0.01221864906974642,0.04154627749508764,0.010849130255828966,-0.09643212009649671,0.0053595696743599965,0.18247860592758275,-0.023779257256064865,-0.31617845375277914,-0.04476388565377762,0.5158864784278007,0.6571987225792911,0.3773551352142041,0.10956627282118277,0.013112257957229239])
        case 'db13':
            coefficients = np.array([5.2200350984548e-07,-4.700416479360808e-06,1.0441930571407941e-05,3.067853757932436e-05,-0.0001651289885565057,4.9251525126285676e-05,0.000932326130867249,-0.0013156739118922766,-0.002761911234656831,0.007255589401617119,0.003923941448795577,-0.02383142071032781,0.002379972254052227,0.056139477100276156,-0.026488406475345658,-0.10580761818792761,0.07294893365678874,0.17947607942935084,-0.12457673075080665,-0.31497290771138414,0.086985726179645,0.5888895704312119,0.6110558511587811,0.3119963221604349,0.08286124387290195,0.009202133538962279])
        case 'db14':
            coefficients = np.array([-1.7871399683109222e-07,1.7249946753674012e-06,-4.389704901780418e-06,-1.0337209184568496e-05,6.875504252695734e-05,-4.177724577037067e-05,-0.00038683194731287514,0.0007080211542354048,0.001061691085606874,-0.003849638868019787,-0.0007462189892638753,0.01278949326634007,-0.0056150495303375755,-0.030185351540353976,0.02698140830794797,0.05523712625925082,-0.0715489555039835,-0.0867484115681106,0.13998901658445695,0.13839521386479153,-0.2180335299932165,-0.27168855227867705,0.21867068775886594,0.6311878491047198,0.5543056179407709,0.25485026779256437,0.062364758849384874,0.0064611534600864905])
        case 'db15':
            coefficients = np.array([6.133359913303714e-08,-6.316882325879451e-07,1.8112704079399406e-06,3.3629871817363823e-06,-2.8133296266037558e-05,2.579269915531323e-05,0.00015589648992055726,-0.00035956524436229364,-0.0003734823541372647,0.0019433239803823459,-0.00024175649075894543,-0.0064877345603061454,0.005101000360422873,0.015083918027862582,-0.020810050169636805,-0.02576700732836694,0.054780550584559995,0.033877143923563204,-0.11112093603713753,-0.0396661765557336,0.19014671400708816,0.06528295284876569,-0.28888259656686216,-0.19320413960907623,0.33900253545462167,0.6458131403572103,0.4926317717079753,0.20602386398692688,0.04674339489275062,0.004538537361577376])
        case 'db16':
            coefficients = np.array([-2.1093396300980412e-08,2.3087840868545578e-07,-7.363656785441815e-07,-1.0435713423102517e-06,1.133660866126152e-05,-1.394566898819319e-05,-6.103596621404321e-05,0.00017478724522506327,0.00011424152003843815,-0.0009410217493585433,0.00040789698084934395,0.00312802338120381,-0.0036442796214883506,-0.006990014563390751,0.013993768859843242,0.010297659641009963,-0.036888397691556774,-0.007588974368642594,0.07592423604445779,-0.006239722752156254,-0.13238830556335474,0.027340263752899923,0.21119069394696974,-0.02791820813292813,-0.3270633105274758,-0.08975108940236352,0.44029025688580486,0.6373563320829833,0.43031272284545874,0.1650642834886438,0.03490771432362905,0.0031892209253436892])
        case 'db17':
            coefficients = np.array([7.26749296856637e-09,-8.423948446008154e-08,2.9577009333187617e-07,3.0165496099963414e-07,-4.505942477225963e-06,6.990600985081294e-06,2.318681379876164e-05,-8.204803202458212e-05,-2.5610109566546042e-05,0.0004394654277689454,-0.00032813251941022427,-0.001436845304805,0.0023012052421511474,0.002967996691518064,-0.008602921520347815,-0.0030429899813869555,0.022733676583919053,-0.0032709555358783646,-0.04692243838937891,0.022312336178011833,0.08110598665408082,-0.05709141963185808,-0.12681569177849797,0.10113548917744287,0.19731058956508457,-0.12659975221599248,-0.32832074836418546,0.027314970403312946,0.5183157640572823,0.6109966156850273,0.3703507241528858,0.13121490330791097,0.025985393703623173,0.00224180700103879])
        case 'db18':
            coefficients = np.array([-2.507934454941929e-09,3.06883586303703e-08,-1.1760987670250871e-07,-7.691632689865049e-08,1.768712983622886e-06,-3.3326344788769603e-06,-8.520602537423464e-06,3.741237880730847e-05,-1.535917123021341e-07,-0.00019864855231101547,0.0002135815619103188,0.0006284656829644715,-0.0013405962983313922,-0.0011187326669886426,0.004943343605456594,0.00011863003387493042,-0.013051480946517112,0.006262167954438661,0.026670705926689853,-0.023733210395336858,-0.04452614190225633,0.05705124773905827,0.0648872162123582,-0.10675224665906288,-0.09233188415030412,0.16708131276294505,0.14953397556500755,-0.21648093400458224,-0.2936540407357981,0.14722311196952223,0.571801654887122,0.5718268077650818,0.31467894133619284,0.10358846582214751,0.01928853172409497,0.0015763102184365595])
        case 'db19':
            coefficients = np.array([8.666848839034483e-10,-1.1164020670405678e-08,4.636937775802368e-08,1.447088298804088e-08,-6.86275565779811e-07,1.531931476697877e-06,3.0109643163099385e-06,-1.664017629722462e-05,5.105950487090694e-06,8.711270467250443e-05,-0.00012460079173506306,-0.0002606761356811995,0.0007358025205041731,0.00034180865344939543,-0.002687551800734441,0.0007689543592242488,0.007040747367080495,-0.005866922281112195,-0.013988388678695632,0.019375549889114482,0.021623767409452484,-0.04567422627778492,-0.026501236250778635,0.0869067555554507,0.02758435062488713,-0.14278569504021468,-0.03351854190320226,0.21234974330662043,0.07465226970806647,-0.28583863175723145,-0.22809139421653665,0.2608949526521201,0.6017045491300916,0.5244363774668862,0.26438843174202237,0.08127811326580564,0.01428109845082521,0.0011086697631864314])
        case 'db20':
            coefficients = np.array([-2.998836489615753e-10,4.05612705554717e-09,-1.814843248297622e-08,2.0143220235374613e-10,2.633924226266962e-07,-6.847079596993149e-07,-1.0119940100181473e-06,7.241248287663791e-06,-4.376143862182197e-06,-3.710586183390615e-05,6.774280828373048e-05,0.00010153288973669777,-0.0003851047486990061,-5.349759844340453e-05,0.0013925596193045254,-0.0008315621728772474,-0.003581494259744107,0.00442054238676635,0.0067216273018096935,-0.013810526137727442,-0.008789324924555765,0.03229429953011916,0.0058746818113949465,-0.061722899624668884,0.005632246857685454,0.10229171917513397,-0.024716827337521424,-0.1554587507060453,0.039850246458519104,0.22829105082013823,-0.016727088308801888,-0.3267868004335376,-0.13921208801128787,0.36150229873889705,0.6104932389378558,0.4726961853103315,0.21994211355113222,0.06342378045900529,0.010549394624937735,0.0007799536136659112])
        case 'sym2':
            coefficients = np.array([-0.12940952255092145,0.22414386804185735,0.836516303737469,0.48296291314469025])
        case 'sym3':
            coefficients = np.array([0.035226291882100656,-0.08544127388224149,-0.13501102001039084,0.4598775021193313,0.8068915093133388,0.3326705529509569])
        case 'sym4':
            coefficients = np.array([-0.07576571478927333,-0.02963552764599851,0.49761866763201545,0.8037387518059161,0.29785779560527736,-0.09921954357684722,-0.012603967262037833,0.0322231006040427])
        case 'sym5':
            coefficients = np.array([0.027333068345077982,0.029519490925774643,-0.039134249302383094,0.1993975339773936,0.7234076904024206,0.6339789634582119,0.01660210576452232,-0.17532808990845047,-0.021101834024758855,0.019538882735286728])
        case 'sym6':
            coefficients = np.array([0.015404109327027373,0.0034907120842174702,-0.11799011114819057,-0.048311742585633,0.4910559419267466,0.787641141030194,0.3379294217276218,-0.07263752278646252,-0.021060292512300564,0.04472490177066578,0.0017677118642428036,-0.007800708325034148])
        case 'sym7':
            coefficients = np.array([0.002681814568257878,-0.0010473848886829163,-0.01263630340325193,0.03051551316596357,0.0678926935013727,-0.049552834937127255,0.017441255086855827,0.5361019170917628,0.767764317003164,0.2886296317515146,-0.14004724044296152,-0.10780823770381774,0.004010244871533663,0.010268176708511255])
        case 'sym8':
            coefficients = np.array([-0.0033824159510061256,-0.0005421323317911481,0.03169508781149298,0.007607487324917605,-0.1432942383508097,-0.061273359067658524,0.4813596512583722,0.7771857517005235,0.3644418948353314,-0.05194583810770904,-0.027219029917056003,0.049137179673607506,0.003808752013890615,-0.01495225833704823,-0.0003029205147213668,0.0018899503327594609])
        case 'sym9':
            coefficients = np.array([0.0014009155259146807,0.0006197808889855868,-0.013271967781817119,-0.01152821020767923,0.03022487885827568,0.0005834627461258068,-0.05456895843083407,0.238760914607303,0.717897082764412,0.6173384491409358,0.035272488035271894,-0.19155083129728512,-0.018233770779395985,0.06207778930288603,0.008859267493400484,-0.010264064027633142,-0.0004731544986800831,0.0010694900329086053])
        case 'sym10':
            coefficients = np.array([0.0007701598091144901,9.563267072289475e-05,-0.008641299277022422,-0.0014653825813050513,0.0459272392310922,0.011609893903711381,-0.15949427888491757,-0.07088053578324385,0.47169066693843925,0.7695100370211071,0.38382676106708546,-0.03553674047381755,-0.0319900568824278,0.04999497207737669,0.005764912033581909,-0.02035493981231129,-0.0008043589320165449,0.004593173585311828,5.7036083618494284e-05,-0.0004593294210046588])
        case 'sym11':
            coefficients = np.array([0.00017172195069934854,-3.8795655736158566e-05,-0.0017343662672978692,0.0005883527353969915,0.00651249567477145,-0.009857934828789794,-0.024080841595864003,0.0370374159788594,0.06997679961073414,-0.022832651022562687,0.09719839445890947,0.5720229780100871,0.7303435490883957,0.23768990904924897,-0.2046547944958006,-0.1446023437053156,0.03526675956446655,0.04300019068155228,-0.0020034719001093887,-0.006389603666454892,0.00011053509764272153,0.0004892636102619239])
        case 'sym12':
            coefficients = np.array([0.00011196719424656033,-1.1353928041541452e-05,-0.0013497557555715387,0.00018021409008538188,0.007414965517654251,-0.0014089092443297553,-0.024220722675013445,0.0075537806116804775,0.04917931829966084,-0.03584883073695439,-0.022162306170337816,0.39888597239022,0.7634790977836572,0.46274103121927235,-0.07833262231634322,-0.17037069723886492,0.01530174062247884,0.05780417944550566,-0.0026043910313322326,-0.014589836449234145,0.00030764779631059454,0.002350297614183465,-1.8158078862617515e-05,-0.0001790665869750869])
        case 'sym13':
            coefficients = np.array([6.820325263075319e-05,-3.573862364868901e-05,-0.0011360634389281183,-0.0001709428585302221,0.0075262253899681,0.005296359738725025,-0.02021676813338983,-0.017211642726299048,0.013862497435849205,-0.0597506277179437,-0.12436246075153011,0.19770481877117801,0.6957391505614964,0.6445643839011856,0.11023022302137217,-0.14049009311363403,0.008819757670420546,0.09292603089913712,0.017618296880653084,-0.020749686325515677,-0.0014924472742598532,0.0056748537601224395,0.00041326119884196064,-0.0007213643851362283,3.690537342319624e-05,7.042986690694402e-05])
        case 'sym14':
            coefficients = np.array([-2.5879090265397886e-05,1.1210865808890361e-05,0.00039843567297594335,-6.286542481477636e-05,-0.002579441725933078,0.0003664765736601183,0.01003769371767227,-0.002753774791224071,-0.029196217764038187,0.004280520499019378,0.03743308836285345,-0.057634498351326995,-0.03531811211497973,0.39320152196208885,0.7599762419610909,0.4753357626342066,-0.05811182331771783,-0.15999741114652205,0.02589858753104667,0.06982761636180755,-0.002365048836740385,-0.019439314263626713,0.0010131419871842082,0.004532677471945648,-7.321421356702399e-05,-0.0006057601824664335,1.9329016965523917e-05,4.4618977991475265e-05])
        case 'sym15':
            coefficients = np.array([9.712419737963348e-06,-7.35966679891947e-06,-0.00016066186637495343,5.512254785558665e-05,0.0010705672194623959,-0.0002673164464718057,-0.0035901654473726417,0.003423450736351241,0.01007997708790567,-0.01940501143093447,-0.03887671687683349,0.021937642719753955,0.04073547969681068,-0.04108266663538248,0.11153369514261872,0.5786404152150345,0.7218430296361812,0.2439627054321663,-0.1966263587662373,-0.1340562984562539,0.06839331006048024,0.06796982904487918,-0.008744788886477952,-0.01717125278163873,0.0015261382781819983,0.003481028737064895,-0.00010815440168545525,-0.00040216853760293483,2.171789015077892e-05,2.866070852531808e-05])
        case 'sym16':
            coefficients = np.array([6.230006701220761e-06,-3.113556407621969e-06,-0.00010943147929529757,2.8078582128442894e-05,0.0008523547108047095,-0.0001084456223089688,-0.0038809122526038786,0.0007182119788317892,0.012666731659857348,-0.0031265171722710075,-0.031051202843553064,0.004869274404904607,0.032333091610663785,-0.06698304907021778,-0.034574228416972504,0.39712293362064416,0.7565249878756971,0.47534280601152273,-0.054040601387606135,-0.15959219218520598,0.03072113906330156,0.07803785290341991,-0.003510275068374009,-0.024952758046290123,0.001359844742484172,0.0069377611308027096,-0.00022211647621176323,-0.0013387206066921965,3.656592483348223e-05,0.00016545679579108483,-5.396483179315242e-06,-1.0797982104319795e-05])
        case 'sym17':
            coefficients = np.array([4.297343327345983e-06,2.7801266938414138e-06,-6.293702597554192e-05,-1.3506383399901165e-05,0.0004759963802638669,-0.000138642302680455,-0.0027416759756816018,0.0008567700701915741,0.010482366933031529,-0.004819212803176148,-0.03329138349235933,0.01790395221434112,0.10475461484223211,0.0172711782105185,-0.11856693261143636,0.1423983504146782,0.6507166292045456,0.681488995344925,0.18053958458111286,-0.15507600534974825,-0.08607087472073338,0.016158808725919346,-0.007261634750928767,-0.01803889724191924,0.009952982523509598,0.012396988366648726,-0.001905407689852666,-0.003932325279797902,5.8400428694052584e-05,0.0007198270642148971,2.520793314082878e-05,-7.607124405605129e-05,-2.4527163425833e-06,3.7912531943321266e-06])
        case 'sym18':
            coefficients = np.array([2.6126125564836423e-06,1.354915761832114e-06,-4.5246757874949856e-05,-1.4020992577726755e-05,0.00039616840638254753,7.021273459036268e-05,-0.002313871814506099,-0.00041152110923597756,0.009502164390962365,0.001642986397278216,-0.030325091089369604,-0.005077085160757053,0.08421992997038655,0.03399566710394736,-0.15993814866932407,-0.052029158983952786,0.47396905989393956,0.7536291401017928,0.40148386057061813,-0.032480573290138676,-0.07379920729060717,0.028529597039037808,0.006277944554311694,-0.03171268473181454,-0.0032607442000749834,0.015012356344250213,0.001087784789595693,-0.005239789683026608,-0.00018877623940755607,0.0014280863270832796,4.741614518373667e-05,-0.0002658301102424104,-9.858816030140058e-06,2.955743762093081e-05,7.847298055831765e-07,-1.5131530692371587e-06])
        case 'sym19':
            coefficients = np.array([5.487732768215838e-07,-6.463651303345963e-07,-1.1880518269823984e-05,8.873312173729286e-06,0.0001155392333357879,-4.612039600210587e-05,-0.000635764515004334,0.00015915804768084938,0.0021214250281823303,-0.0011607032572062486,-0.005122205002583014,0.007968438320613306,0.01579743929567463,-0.02265199337824595,-0.046635983534938946,0.0070155738571741596,0.008954591173043624,-0.06752505804029409,0.10902582508127781,0.578144945338605,0.7195555257163943,0.2582661692372836,-0.17659686625203097,-0.11624173010739675,0.09363084341589714,0.08407267627924504,-0.016908234861345205,-0.02770989693131125,0.004319351874894969,0.008262236955528255,-0.0006179223277983108,-0.0017049602611649971,0.00012930767650701415,0.0002762187768573407,-1.6821387029373716e-05,-2.8151138661550245e-05,2.0623170632395688e-06,1.7509367995348687e-06])
        case 'sym20':
            coefficients = np.array([3.695537474835221e-07,-1.9015675890554106e-07,-7.919361411976999e-06,3.025666062736966e-06,7.992967835772481e-05,-1.928412300645204e-05,-0.0004947310915672655,7.215991188074035e-05,0.002088994708190198,-0.0003052628317957281,-0.006606585799088861,0.0014230873594621453,0.01700404902339034,-0.003313857383623359,-0.031629437144957966,0.008123228356009682,0.025579349509413946,-0.07899434492839816,-0.02981936888033373,0.4058314443484506,0.75116272842273,0.47199147510148703,-0.0510883429210674,-0.16057829841525254,0.03625095165393308,0.08891966802819956,-0.0068437019650692274,-0.035373336756604236,0.0019385970672402002,0.012157040948785737,-0.0006111263857992088,-0.0034716478028440734,0.0001254409172306726,0.0007476108597820572,-2.6615550335516086e-05,-0.00011739133516291466,4.525422209151636e-06,1.22872527779612e-05,-3.2567026420174407e-07,-6.329129044776395e-07])
        case 'coif1':
            coefficients = np.array([-0.01565572813546454,-0.0727326195128539,0.38486484686420286,0.8525720202122554,0.3378976624578092,-0.0727326195128539])
        case 'coif2':
            coefficients = np.array([-0.0007205494453645122,-0.0018232088707029932,0.0056114348193944995,0.023680171946334084,-0.0594344186464569,-0.0764885990783064,0.41700518442169254,0.8127236354455423,0.3861100668211622,-0.06737255472196302,-0.04146493678175915,0.016387336463522112])
        case 'coif3':
            coefficients = np.array([-3.459977283621256e-05,-7.098330313814125e-05,0.0004662169601128863,0.0011175187708906016,-0.0025745176887502236,-0.00900797613666158,0.015880544863615904,0.03455502757306163,-0.08230192710688598,-0.07179982161931202,0.42848347637761874,0.7937772226256206,0.4051769024096169,-0.06112339000267287,-0.0657719112818555,0.023452696141836267,0.007782596427325418,-0.003793512864491014])
        case 'coif4':
            coefficients = np.array([-1.7849850030882614e-06,-3.2596802368833675e-06,3.1229875865345646e-05,6.233903446100713e-05,-0.00025997455248771324,-0.0005890207562443383,0.0012665619292989445,0.003751436157278457,-0.00565828668661072,-0.015211731527946259,0.025082261844864097,0.03933442712333749,-0.09622044203398798,-0.06662747426342504,0.4343860564914685,0.782238930920499,0.41530840703043026,-0.05607731331675481,-0.08126669968087875,0.026682300156053072,0.016068943964776348,-0.0073461663276420935,-0.0016294920126017326,0.0008923136685823146])
        case 'coif5':
            coefficients = np.array([-9.517657273819165e-08,-1.6744288576823017e-07,2.0637618513646814e-06,3.7346551751414047e-06,-2.1315026809955787e-05,-4.134043227251251e-05,0.00014054114970203437,0.00030225958181306315,-0.0006381313430451114,-0.0016628637020130838,0.0024333732126576722,0.006764185448053083,-0.009164231162481846,-0.01976177894257264,0.03268357426711183,0.0412892087501817,-0.10557420870333893,-0.06203596396290357,0.4379916261718371,0.7742896036529562,0.4215662066908515,-0.05204316317624377,-0.09192001055969624,0.02816802897093635,0.023408156785839195,-0.010131117519849788,-0.004159358781386048,0.0021782363581090178,0.00035858968789573785,-0.00021208083980379827])
        case 'meyer':
            coefficients = np.array([0.0,-1.009999956941423e-12,8.519459636796214e-09,-1.111944952595278e-08,-1.0798819539621958e-08,6.066975741351135e-08,-1.0866516536735883e-07,8.200680650386481e-08,1.1783004497663934e-07,-5.506340565252278e-07,1.1307947017916706e-06,-1.489549216497156e-06,7.367572885903746e-07,3.20544191334478e-06,-1.6312699734552807e-05,6.554305930575149e-05,-0.0006011502343516092,-0.002704672124643725,0.002202534100911002,0.006045814097323304,-0.006387718318497156,-0.011061496392513451,0.015270015130934803,0.017423434103729693,-0.03213079399021176,-0.024348745906078023,0.0637390243228016,0.030655091960824263,-0.13284520043622938,-0.035087555656258346,0.44459300275757724,0.7445855923188063,0.44459300275757724,-0.035087555656258346,-0.13284520043622938,0.030655091960824263,0.0637390243228016,-0.024348745906078023,-0.03213079399021176,0.017423434103729693,0.015270015130934803,-0.011061496392513451,-0.006387718318497156,0.006045814097323304,0.002202534100911002,-0.002704672124643725,-0.0006011502343516092,6.554305930575149e-05,-1.6312699734552807e-05,3.20544191334478e-06,7.367572885903746e-07,-1.489549216497156e-06,1.1307947017916706e-06,-5.506340565252278e-07,1.1783004497663934e-07,8.200680650386481e-08,-1.0866516536735883e-07,6.066975741351135e-08,-1.0798819539621958e-08,-1.111944952595278e-08,8.519459636796214e-09,-1.009999956941423e-12])
        case 'vaid2'|'vaid':
            coefficients = np.array([-0.2638026e+01,0.7154463,-0.2598479,0.6388361e-01])
        case 'vaid3':
            coefficients = np.array([-0.3676246e+01,0.1100022e+01,-0.5170637,0.236283,-0.8441314e-01,0.1716341e-01])
        case _:
            # Incase a wavelet is used which hasn't been set up
            print('no coefficients for wavelet')

    return coefficients

def getFilters(mother_wavelet):
    # getFilters returns four filters using the process outlined in:
    # https://www.mathworks.com/help/wavelet/ug/fast-wavelet-transform-fwt-algorithm.html?ue

    # Scaling filter coefficients are retrieved from getCoefficiets:
    coefficients = getCoefficients(mother_wavelet)

    # The low pass reconstruction filter is calculated by normalising the scaling filter
    lpf_R = coefficients/np.linalg.norm(coefficients)
    
    # Initialising the high pass reconstruction filter
    hpf_R = np.array(lpf_R)
    filter_length = len(lpf_R)
    
    # The high pass reconstruction filter is a 'quadrature mirror' of the low pass reconstruction,
    # This is defined as:
    for k in range(filter_length):
        hpf_R[k] = ((-1)**k) * lpf_R[filter_length+1-k-2]

    # Low and high pass decomposition filters are 'reversed' from the reconstruction filters:
    # i.e., [ 1 , -2 ] -> [ -2 , 1 ]
    lpf_D = lpf_R[::-1]
    hpf_D = hpf_R[::-1]

    return lpf_D, hpf_D, lpf_R, hpf_R

def dwt(f, lpf_D, hpf_D):
    # Dwt (discrete wavelet transform) decomposes a signal into its wavelet coefficient arrays
    # Using the high and low pass decomposition filters derived from the mother wavelet
    
    # The signal is convolved with the low and high pass filters, and downsampled by 2x

    # cA, the low-pass coefficients, are referred to as 'approximate coefficients'
    cA = np.convolve(f,lpf_D)[::2] #the [::2] removes every second value / downsamples by 2

    # cD, the high-pass coefficients, are reffered to as 'detail coefficients'
    cD = np.convolve(f,hpf_D)[::2]

    # The approximate and detail coefficient arrays capture low and high frequency information respectively
    
    return [cA, cD]

def idwt(cA,cD,match_length,lpf_R,hpf_R):
    # idwt (inverse discrete wavelet transform) 
    # Reconstructs a signal from its approximate and detail wavelet coefficient arrays
    # using the high-pass and low-pass reconstruction filters.
    
    # Zeros are inserted at every odd index, referred to as 'upsampling'
    cA2 = np.zeros(len(cA)*2-1)
    cA2[::2] = cA
    cD2 = np.zeros(len(cD)*2-1)
    cD2[::2] = cD

    # The upsampled approximate and detail coefficient arrays are convolved
    # with the reconstruction low and high pass filters respectively, and linearly summed:
    w = np.convolve(cA2,lpf_R) + np.convolve(cD2,hpf_R)

    # This process generates additional values at the edges of the signal, so these values
    # must be removed to return a signal of the same length as the original (match_length).
    reconstructed = w[ceil((len(w)-match_length)/2):len(w)-floor((len(w)-match_length)/2)]

    return reconstructed

def dwt2(f, lpf_D, hpf_D):
    # Dwt (discrete wavelet transform) decomposes a signal into its wavelet coefficient arrays
    # Using the high and low pass decomposition filters derived from the mother wavelet

    # The signal is convolved with the low and high pass filters, and downsampled by 2x

    # cA, the low-pass coefficients, are referred to as 'approximate coefficients'
    print(np.convolve(f,lpf_D))
    cA = np.convolve(f,lpf_D,mode='same')[::2] #the [::2] removes every second value / downsamples by 2

    # cD, the high-pass coefficients, are reffered to as 'detail coefficients'
    cD = np.convolve(f,hpf_D,mode='same')[::2]

    # The approximate and detail coefficient arrays capture low and high frequency information respectively

    return [cA, cD]

def idwt2(cA,cD,match_length,lpf_R,hpf_R):
    # idwt (inverse discrete wavelet transform) 
    # Reconstructs a signal from its approximate and detail wavelet coefficient arrays
    # using the high-pass and low-pass reconstruction filters.
    
    # Zeros are inserted at every odd index, referred to as 'upsampling'
    cA2 = np.zeros(len(cA)*2)
    print(cA2)
    cA2[::2] = cA
    print(cA2)
    cD2 = np.zeros(len(cD)*2)
    cD2[::2] = cD

    # The upsampled approximate and detail coefficient arrays are convolved
    # with the reconstruction low and high pass filters respectively, and linearly summed:
    w = np.convolve(cA2,lpf_R,mode='same') + np.convolve(cD2,hpf_R,mode='same')

    # This process generates additional values at the edges of the signal, so these values
    # must be removed to return a signal of the same length as the original (match_length).
    reconstructed = w

    return reconstructed

##
## decomposiiton
##

def multires(signal, level, lpf_D, hpf_D):
    # multires (Multiple-resolution analysis) repeatedly decomposes the approximate coefficients
    # Because the approximate coefficients represent the low frequency part of the signal,
    # each level analyses a lower frequency portion of the signal.

    # This process of multi-resolution analysis is shown below:
    # 
    # [signal]──┬─>[cD1] ┄┄┄┄┄┄┄┄┄┄┄┄┄┄[cD1]        level 1
    #           └─>[cA1]──┬─>[cD2]┄┄┄┄┄[cD2]        level 2
    #                     └─>[cA2]──┬─>[cD3]        level 3
    #                               └─>[cA3]
    # 
    # Each decomposition splits the signal into a higher and lower frequency component,
    # so the frequencies spanned by the final sets of coefficients
    # for a signal sampled at 1000 Hz, decomposed to level 3 as above would be:
    #
    #   cD1: 1000 - 500 Hz
    #   cD2: 500 - 250 Hz
    #   cD3: 250 - 125 Hz
    #   cA3: 125 - 0 Hz

    # An array is used to store the coefficients at each resolution
    coefficientArray = []

    # For the first decomposition, the original signal is used.
    # Each successive decomposition uses the approximate coefficients of the previous level
    cA = signal

    for i in range(level):
        # At each level, the approximate coefficients are decomposed into
        # low and high frequency components using the discrete wavelet transform.
        [cA, cD] = dwt(cA, lpf_D, hpf_D)

        # Only the detail (high frequency) coefficients are stored, as the 
        # approximate coefficients are used in the following iteration.
        coefficientArray.append(cD)

    # Finally, the last approximate coefficients are added to the end of the array
    coefficientArray.append(cA)

    return coefficientArray

def inverseMultires(signal, coefficientArray, lpf_R, hpf_R):
    # inverseMultires reconstructs the original signal from the
    # set of coefficients generated by multi-resolution analysis.

    # This process works in reverse to multi-resolution decomposition,
    # iteratively reconstructing each approximate coefficient array from the lower level:

    # [cD1]──────────────────────┬─>[signal]
    # [cD2]────────────┬─>[cA1]──┘
    # [cD3]──┬─>[cA2]──┘
    # [cA3]──┘

    # The initial approximate coefficients are the last in the coefficient array
    
    cA = coefficientArray[len(coefficientArray)-1]

    # The number of levels to reconstruct is determined by the length of the provided array
    for i in range(len(coefficientArray)-1):

        # Detail coefficients are set appropriately at each level
        cD = coefficientArray[(len(coefficientArray)-2)-i]

        # The inverse discrete wavelet transform must know the appropriate length of the reconstruction.
        # This is set to match the detail coefficients of the level above at each iteration,
        # and is set to match the original signal for the final reconstruction.
        if (i==(len(coefficientArray)-2)):
            match_length = len(signal)
        else:
            match_length = len(coefficientArray[(len(coefficientArray)-3)-i])

        # The higher level approximate coefficients are reconstructed from the 
        # lower level detail and approximate coefficients:
        reconstructed = idwt(cA, cD, match_length, lpf_R, hpf_R)

        # Finally, the approximate coefficient is reset for the next iteration.
        cA = reconstructed

    # After all reconstructions, the fully reconstructed signal is returned
    return reconstructed

def getScaledDecompositionLevels(signals,max_level=10):
    ## returns the decomposition levels scaled to the average PSD amplitudes of 'signals'.
    # signals should be either a single recording, or a list of recordings all of same sample rate fs
    fs = 1 #sampling frequency only for maths

    if not type(signals)==list: #ensure list format
        signals = [signals]

    #initialise PSD array
    (f,S)=scipy.signal.periodogram(signals[0],fs,scaling='density')
    sums = np.zeros((len(f))).astype(np.float64)

    for sig in signals:
        (f,S)=scipy.signal.periodogram(sig.astype(np.float64),fs,scaling='density',return_onesided=True)
        if (len(S)==len(sums)):
            sums += np.array(S)
        # else: print(f'a recording had different N: {len(S)} vs {len(sums)}')
    
    S = sums/len(signals) # average S over signals
    
    S_mean = np.mean(S)

    ## for plotting the psd
    # fig = plt.figure()
    # fig.set_size_inches(5,3)
    # ax = fig.add_subplot(111)
    # ax.plot(f*96000,S,color='black')
    # ax.set_xlabel('Frequency (Hz)')
    # ax.set_ylabel('PSD (dB/Hz)')
    # plt.subplots_adjust(bottom=0.15, left=0.15)
    # plt.xlim((0,96000/2))
    # plt.ylim(bottom=0)
    # plt.show()

    ## first split the PSD into 2^k bands (i.e. max decomposition)
    min_bandwidth = int(len(f)/(2**max_level))

    decompose_to_max_level = [1]*(2**max_level)

    for k in range(len(decompose_to_max_level)):
        band_coeffs = S[min_bandwidth*k : min_bandwidth*k+min_bandwidth]
        if np.mean(band_coeffs)<S_mean:
            # lower decomposition level of lower power bands
            decompose_to_max_level[k]=0

    decomp_levels = [1]*len(decompose_to_max_level)
    for i in range(1,max_level):
        width = int((2**max_level)/2**i)
        for j in range(int((2**max_level)/width)):
            if 1 in decompose_to_max_level[j*width:j*width+width]:
                for k in range(j*width,j*width+width):
                    decomp_levels[k]+=1

    ## for plotting the psd
    # fig = plt.figure()
    # fig.set_size_inches(5,3)
    # ax = fig.add_subplot(111)
    # ax.plot(decomp_levels,color='black',linestyle='',marker='.')
    # ax.set_xlabel('Decomposition level k (No units)')
    # ax.set_ylabel('Decomposition depth (No units)')
    # plt.subplots_adjust(bottom=0.15, left=0.15)
    # plt.show()

    # decomp levels looks like:         [3, 3, 4, 4, 2, 2, 2, 2, 3, 3, 4, 4, 2, 2, 2, 2]
    # scaled levels will look like:     [3,1,0,0,2,1,0,0]

    # print(f'min bandwidth: {min_bandwidth}')

    reflected_decomp_levels = [0]*len(decompose_to_max_level)
    scaled_decomp_levels = [0]

    current_level = 0
    scaled_count = 0
    startI=0

    while_catch = 0
    while not reflected_decomp_levels==decomp_levels:
        index_range = len(reflected_decomp_levels)//2**current_level
        
        endI=startI+index_range

        # print(f'scaled count: {scaled_count},start i: {startI}, index range: {index_range}')
        ## if any of the decomposition levels in the current range need to increase, do so
        if any(decomp_levels[i]>reflected_decomp_levels[i] for i in range(startI,endI)):
            # print(f'need to increase level from reflected range {startI} to {endI} at scaled_count {scaled_count} in {scaled_decomp_levels}')
            scaled_decomp_levels.insert(scaled_count,scaled_decomp_levels[scaled_count]+1) #increase level by 1
            scaled_decomp_levels[scaled_count+1]=0 #and duplicate to reflect split coeffs
            current_level+=1

            for i in range(startI,endI):
                reflected_decomp_levels[i] += 1
            # print(f'scaled_decomp_levels: {scaled_decomp_levels}')
            # print(f'reflected_decomp_levels: {reflected_decomp_levels}')
        else: 
            scaled_count+=1
            startI+=index_range
            current_level=reflected_decomp_levels[startI]

        while_catch+=1
        if(while_catch>5000):
            print('\nEncountered while catch: breaking while loop\n')
            break

    return scaled_decomp_levels, decomp_levels

def scaledres(signal,levels,lpf_D,hpf_D):
    # An array is used to store the coefficients
    coefficientArray = []

    # For the first decomposition, the original signal is used.
    # Each successive decomposition uses the approximate coefficients of the previous level
    coefficientArray = [signal]
    lengthsArray = [len(signal)]

    current_level = 0
    coefficient_array_index = 0
    levels_count = 0
    while levels_count<len(levels):
        to_decompose = coefficientArray[coefficient_array_index]
        if levels[levels_count]>current_level:
            #decompose this
            [cA,cD]=dwt(to_decompose,lpf_D,hpf_D)
            coefficientArray[coefficient_array_index]=cD
            coefficientArray.insert(coefficient_array_index,cA)
            current_level+=1
            if len(cA)<min(lengthsArray):
                lengthsArray.append(len(cA))
        else:
            coefficient_array_index+=1
            current_level = 0
            levels_count+=1

    return coefficientArray,lengthsArray

def scaledresInverse(lengthsArray,levels,coeffs,lpf_R,hpf_R):
    # print('starting inverse, lengths of levels:')
    # for i in coeffs: print(len(i))
    
    for level_count in range(len(lengthsArray)-1):
        # print(f'level count is {level_count}')
        min_len = min(len(i) for i in coeffs)
        new_min_len = min(i for i in lengthsArray if i>min_len)
        # print(f'min_len {min_len}')
        # print(f'new_min_len {new_min_len}')

        for i,coeff in enumerate(coeffs):
            if len(coeff)==min_len:
                # print(f'at index {i}, reconstructing')
                #reconstruct index i
                # for l in coeffs: print(len(l))
                reconstructed = idwt(coeffs[i],coeffs[i+1],new_min_len,lpf_R,hpf_R)
                coeffs.pop(i+1)
                coeffs[i] = reconstructed
                # print(f'coeffs lengths post reconstruction:')
                # for l in coeffs: print(len(l))
    #final reconstruction
    # cA,cD = coeffs
    # reconstructed = idwt(cA,cD,lengthsArray[0],lpf_R,hpf_R)
    reconstructed = coeffs[0]

    return reconstructed

def fullres(signal,level,lpf_D,hpf_D):
    # An array is used to store the coefficients at each resolution
    # For the first decomposition, the original signal is used.
    # Each successive decomposition uses the coefficients of the previous level
    cA = signal
    coeffs = [cA]
    match_lengths = [len(cA)]

    for i in range(level):
        new_coeffs = []

        for j in range(len(coeffs)):
            [cA,cD] = dwt(coeffs[j],lpf_D,hpf_D)
            new_coeffs.append(cA)
            new_coeffs.append(cD)
        
        coeffs = new_coeffs
        match_lengths.append(len(cA))
        # At each level, all coefficients are decomposed into
        # low and high frequency components using the discrete wavelet transform.

    return coeffs,match_lengths

def fullresInverse(match_lengths,coeffs,lpf_R,hpf_R):
    
    #reverse order of match_lengths
    match_lengths.reverse()

    levels = int(log2(len(coeffs)))
    for i in range(levels):
        # print(f'level {i} of {levels},length of coeffs: {len(coeffs)} matching length {match_lengths[i]}')
        new_coeffs = []
        for j in range(0,len(coeffs),2):
            reconstructed = idwt(coeffs[j],coeffs[j+1],match_lengths[i+1] ,lpf_R,hpf_R)
            new_coeffs.append(reconstructed)
        coeffs = new_coeffs

    # After all reconstructions, the fully reconstructed signal is returned
    return coeffs[0]

##
## noise estimation
##

def normaliseH(H):
    return H

def getHurstThresholds(signal,max_windows=5,fs=96000,overlap=True):
    # overlap is 50%
    # pls signal length in seconds is close to a multiple of window length // 2

    signal_length_seconds = len(signal)/fs
    # 200 samples is min length of window
    num_window = min(max_windows,ceil(len(signal) / 200))

    print(f'frequency band length: {len(signal)}, num_window: {num_window} of max {max_windows}')

    window_length_samples = int(2*len(signal)/(num_window+1))

    H_array = []
    thres_array = []
    H_indices = []

    max_intensity = 3
    min_intensity = 0

    for i in range(num_window):
        window_samples = signal[int(i*window_length_samples/2) : int((i+2)*window_length_samples/2)]
        H, c, val = compute_Hc(window_samples)
        H_array.append(H)
        H_indices.append(int(i*window_length_samples/2))

        intensity = min_intensity + (1 - 7*(H-0.1))*(max_intensity-min_intensity)
        intensity = max(min(intensity, max_intensity), min_intensity)
        abs_window_samples = np.abs(window_samples)
        thres = np.median(abs_window_samples)+intensity*np.std(abs_window_samples)

        thres_array.append(thres)

        # print('H {:<10.2f}, I {:<10.2f}, T {:<10.2f}, start,end: {:<10},{:<10}'.format(H,intensity,thres,int(i*window_length_samples/2),int((i+2)*window_length_samples/2)))
    print(f'Hurst Values:')
    print(H_array)
    
    return thres_array, H_indices, H_array

def normaliseE(E):
    E -= 0.002
    E /= (0.028-0.002)
    return abs(E)

def getEntropyThresholds(signal,max_windows=5,fs=96000,overlap=True):
    # overlap is 50%
    # pls signal length in seconds is close to a multiple of window length // 2

    signal_length_seconds = len(signal)/fs
    # 200 samples is min length of window
    num_window = min(max_windows,ceil(len(signal) / 200))

    print(f'frequency band length: {len(signal)}, num_window: {num_window} of max {max_windows}')

    window_length_samples = int(2*len(signal)/(num_window+1))

    E_array = []
    thres_array = []
    E_indices = []

    max_intensity = 3
    min_intensity = 0

    for i in range(num_window):
        window_samples = signal[int(i*window_length_samples/2) : int((i+2)*window_length_samples/2)]
        # E = scientropy(np.array(window_samples))
        value,counts = np.unique(window_samples, return_counts=True)
        # print(window_samples)
        # print(type(window_samples))
        # print(scientropy(np.array([-9,1,-2,22])))
        # print(np.entropy())
        E = scientropy(counts)/len(counts)
        E_array.append(E)
        E_indices.append(int(i*window_length_samples/2))

        intensity = min_intensity + (1 - normaliseE(E))*(max_intensity-min_intensity)
        intensity = max(min(intensity, max_intensity), min_intensity)
        abs_window_samples = np.abs(window_samples)
        thres = np.median(abs_window_samples)+intensity*np.std(abs_window_samples)

        thres_array.append(thres)

        # print('H {:<10.2f}, I {:<10.2f}, T {:<10.2f}, start,end: {:<10},{:<10}'.format(H,intensity,thres,int(i*window_length_samples/2),int((i+2)*window_length_samples/2)))
    print(f'Entropy Values:')
    print(E_array)
    
    return thres_array, E_indices, E_array

def normaliseS(Std,globalStd=250):
    maxStd = globalStd * 4
    minStd = 50
    Std -= minStd
    Std /= (maxStd-minStd)
    Std = min(1,Std)
    return abs(Std)

def getStdThresholds(signal,max_windows=5,fs=96000,overlap=True,globalMedian=0,globalStd=250,intensity=[0,5]):
    # overlap is 50%
    # pls signal length in seconds is close to a multiple of window length // 2

    signal_length_seconds = len(signal)/fs
    # 200 samples is min length of window
    num_window = min(max_windows,ceil(len(signal) / 200))

    # print(f'frequency band length: {len(signal)}, num_window: {num_window} of max {max_windows}')

    window_length_samples = int(2*len(signal)/(num_window+1))

    E_array = []
    thres_array = []
    E_indices = []

    max_intensity = intensity[1]
    min_intensity = intensity[0]

    for i in range(num_window):
        window_samples = signal[int(i*window_length_samples/2) : int((i+2)*window_length_samples/2)]
        E = np.std(window_samples)
        E_array.append(E)
        E_indices.append(int(i*window_length_samples/2))

        intensity = min_intensity + (1 - normaliseS(E,globalStd))*(max_intensity-min_intensity)
        intensity = max(min(intensity, max_intensity), min_intensity)
        abs_window_samples = np.abs(window_samples)
        # thres = np.median(abs_window_samples)+intensity*np.std(abs_window_samples)
        # thres = np.median(abs_window_samples)*intensity
        thres = globalMedian*intensity

        thres_array.append(thres)

    return thres_array, E_indices, E_array

##
## denoising
##

def threshold_localised(coeffs,threshold_method='hard',windows=5,intensity=[0,5]):
    # std scaled
    # localised calculates a unique threshold for each frequency band, and for each window
    # then values are thresholded according to the (first) window they fall into
    max_windows = windows

    # get overall median:
    globalMedian = np.median([abs(item) for sublist in coeffs for item in sublist])
    globalStd = np.std([abs(item) for sublist in coeffs for item in sublist])
    # print(f'global std: {globalStd}')

    for frequency_band in coeffs:
        noise_levels = []
        thresholds,indices,std_vals = getStdThresholds(frequency_band,max_windows=max_windows,globalMedian=globalMedian,globalStd=globalStd,intensity=intensity)
        # print(f'thresholds are: {thresholds}')

        for k in range(len(frequency_band)):
            thres_index = max(i for i in range(len(indices)) if indices[i]<=k)
            if abs(frequency_band[k])<thresholds[thres_index]:
                frequency_band[k] = 0.001
            elif threshold_method=='soft':
                # In soft thresholding, values higher than the threshold are reduced in magnitude
                # by the threshold amount.
                frequency_band[k] = copysign(abs(frequency_band[k])-thresholds[thres_index],frequency_band[k])
    
    return coeffs

def threshold(coeffs, threshold_method='hard', threshold_selection='universal',thres=0,intensity=1,windows=5):
    # threshold takes a signal decomposed using multi-resolution analysis, and 
    # thresholds every coefficient using 'hard' or 'soft' thresholding.
    # There are a variety of ways to select a threshold value, with the method specified by 'threshold_selection'.
    
    thresholds = []

    if (threshold_selection=='constant'):
        # If a constant threshold is used, this applies to every decomposition level.
        thresholds = [thres]*len(coeffs)
        # print(thresholds)
    
    elif (threshold_selection=='universal'):
        # The most common method is referred to as 'universal' thresholding.
        # this uses the noise level and signal length to calculate a threshold for each level.
        # The noise level is approximated for each level as defined in https://doi.org/10.1088/1741-2552/abc741
        noise_levels = []
        for i in range(len(coeffs)):
            # noise_level = np.median(np.abs(coeffs[i]))/0.6745
            noise_level = np.std(coeffs[i])
            noise_levels.append(noise_level)
    
        signal_len = len(coeffs[0])*2
        thresholds = np.array(noise_levels)*sqrt(2*log(signal_len))

    elif (threshold_selection=='minimax'):
        # Minimax thresholding uses a similar approach to universal thresholding, 
        # however the thresholds are calculated slightly differently, shown here:
        noise_levels = []
        for i in range(len(coeffs)):
            noise_level = np.std(coeffs[i])
            noise_levels.append(noise_level)

        signal_len = len(coeffs[0])*2
        thresholds = np.array(noise_levels)*(0.3936 + 0.1829*log(signal_len,2))

    elif (threshold_selection=='multi-level'):
        # multi-level used in https://doi.org/10.1109/ICAICT.2013.6722677
        # and referenced in https://doi.org/10.1088/1741-2552/abc741 as 'Golroudbari's algorithm'
        noise_levels = []
        for i in range(len(coeffs)):
            j=i+1
            noise_level = (np.median(np.abs(coeffs[i]))/0.6745)/log(j+1)
            noise_levels.append(noise_level)
        # print(noise_levels)
        
        thresholds = np.array(noise_levels)*sqrt(2*log(len(coeffs[0])*2))

    elif (threshold_selection=='custom'):
        noise_levels = []
        print('level freq std')
        for i in range(len(coeffs)):
            noise_level = np.median(np.abs(coeffs[i]))-(intensity*np.std(np.abs(coeffs[i])))
            # print(str(i)+' '+str(96000/(2**(i+1)))+' '+str(np.std(np.abs(coeffs[i]))))
            # print(str(i)+' '+str(96000/(2**(i+2)))+' '+str(np.std(np.abs(coeffs[i]))))
            noise_levels.append(noise_level)
        # print(noise_levels)
        
        thresholds = np.array(noise_levels)*sqrt(2*log(len(coeffs[0])*2))
    
    elif (threshold_selection=='custom_alt_noise_levels'):
        noise_levels = []
        for i in range(len(coeffs)):
            noise_level = np.median(np.abs(coeffs[i]))-(intensity*np.std(np.abs(coeffs[i])))
            noise_levels.append(noise_level)
            # print('level '+str(i+1))
            # print(np.mean(np.abs(coeffs[i])))
            # print(np.median(np.abs(coeffs[i])))
            # print(noise_level)
        # print(noise_levels)
        
        thresholds = np.array(noise_levels)

    elif (threshold_selection=='test_aliasing'):
        noise_levels = []
        for i in range(len(coeffs)):
            if (i==0):
                noise_levels.append(np.max(coeffs[i]*1.1))
            else: noise_levels.append(0)
        # print(noise_levels)
        thresholds = np.array(noise_levels)
    elif (threshold_selection=='test_aliasing_2'):
        noise_levels = []
        for i in range(len(coeffs)):
            if (i==0):
                noise_levels.append(np.mean(np.abs(coeffs[i]))+intensity*np.std(np.abs(coeffs[i])))
            else: noise_levels.append(0)
        # print(noise_levels)
        thresholds = np.array(noise_levels)
    
    elif (threshold_selection=='std_scaled'):
        coeffs = threshold_localised(coeffs,threshold_method=threshold_method,windows=windows,intensity=intensity)
        return coeffs

    # For each of the decomposition level arrays (cA1, cA2, cA3, cD3 etc),
    # Each coefficient in the array is compared to the threshold value.
    for i in range(len(coeffs)):
        for k in range(len(coeffs[i])):
            if abs(coeffs[i][k])<thresholds[i]:
                # In both hard and soft thresholding, values less than the threshold are set to 0
                coeffs[i][k] = 0.001
            elif threshold_method=='soft':
                # In soft thresholding, values higher than the threshold are reduced in magnitude
                # by the threshold amount.
                coeffs[i][k] = copysign(abs(coeffs[i][k])-thresholds[i],coeffs[i][k])
    
    return coeffs

def denoise(signal,level,mother_wavelet='haar',technique='multi_res',threshold_selection='universal',threshold_method='hard', thres=0, intensity=1, storefile=False,fs=96000,levels='',windows=5):
    # denoise takes a signal through the entire wavelet denoising process,
    # by decomposing it with multi-resolution analysis, thresholding it, and reconstructing it.
    # The process diagram is as follows:

    #   [signal]──┬─>[cD1] ┄┄┄┄┄┄┄┄┄┄┄┄┄┄[cD1]──────────────────────┬─>[signal]
    #             └─>[cA1]──┬─>[cD2]┄┄┄┄┄[cD2]────────────┬─>[cA1]──┘
    #                       └─>[cA2]──┬─>[cD3]──┬─>[cA2]──┘
    #                                 └─>[cA3]──┘
    #                                      ^
    #                                 thresholding

    lpf_D, hpf_D, lpf_R, hpf_R = getFilters(mother_wavelet)

    if technique=='multi_res':
        coeffs = multires(signal,level,lpf_D,hpf_D)
        # plot_histogram(coeffs)
        thresholded_coeffs = threshold(coeffs, threshold_method, threshold_selection, thres, intensity, windows=windows)

        denoised_signal = inverseMultires(signal,thresholded_coeffs,lpf_R,hpf_R)
    elif technique=='scaled_res':
        if not levels:
            levels,level_depths = getScaledDecompositionLevels(signal,max_level=level)
        # print(levels)
        
        coeffs,lengthsArray = scaledres(signal,levels,lpf_D,hpf_D)

        # for coeff in coeffs:
        #     print(f'{len(coeff) }',end=' \n')

        thresholded_coeffs = threshold(coeffs, threshold_method, threshold_selection, thres, intensity, windows=windows)
        denoised_signal = scaledresInverse(lengthsArray,levels,thresholded_coeffs,lpf_R,hpf_R)
    elif technique=='full_res':
        coeffs,match_lengths = fullres(signal,level,lpf_D,hpf_D)
        thresholded_coeffs = threshold(coeffs, threshold_method, threshold_selection, thres, intensity)
        denoised_signal = fullresInverse(match_lengths,thresholded_coeffs,lpf_R,hpf_R)

    if (storefile):
        ## write wav files for listening
        wavfile.write('test.wav',fs,signal.astype(np.int16))
        wavfile.write('test_denoised.wav',fs,denoised_signal.astype(np.int16))

    return denoised_signal

##
## eval
##

def SDI(denoised,clean):
    fs = 1 #this doesn't affect the ratio
    (f,clean_PSD)=scipy.signal.periodogram(clean.astype(np.float64),fs,scaling='density',return_onesided=True)
    (f,denoised_PSD)=scipy.signal.periodogram(denoised.astype(np.float64),fs,scaling='density',return_onesided=True)

    ratio = np.sum(np.square(clean_PSD-denoised_PSD))/np.sum(np.square(clean_PSD))

    return -10*log(ratio,10)

def SNR(enhanced,noise):
    S = np.sum(np.square(np.abs(enhanced)))/len(enhanced)
    N = np.sum(np.square(np.abs(noise)))/len(noise)
    if N==0: 
        SNR=INFINITY
    else: SNR=10*log(S/N,10)
    return SNR

def SnNR(signal_plus_noise,noise):
    S_plus_N = np.sum(np.square(np.abs(signal_plus_noise)))/len(signal_plus_noise)
    N = np.sum(np.square(np.abs(noise)))/len(noise)
    if N==0: SnNR=INFINITY
    else: SnNR = 10*log((S_plus_N)/N, 10)
    return SnNR

def PSNR(original,processed):
    # broken

    # max_power=(2**16-1)**2
    # MSE = np.sum(np.square(original-processed))/len(original)
    # PSNR=10*log(max_power/MSE, 10)
    max_sig = np.max(original)
    MSE = np.mean(np.square(original-processed))
    PSNR = 10*log((max_sig**2)/MSE,10)
    return PSNR

def SuccessRatio(noise_pre, noise_post):
    SR = log(np.var(noise_pre)/np.var(noise_post), 10)
    return SR

def PreservationRatio(noise_region_pre,noise_region,signal_region_pre,signal_region):
    PR_1 = np.mean(np.square(noise_region_pre-noise_region))
    PR_2 = np.mean(np.square(signal_region_pre-signal_region))
    return log(PR_1/PR_2,10)

def generateSignal(length_in_seconds,frequency,sampling_rate,amplitude=1):
    time=np.linspace(0,length_in_seconds,int(sampling_rate*length_in_seconds),endpoint=False)
    return amplitude*np.sin(2*np.pi * frequency * time)

##
## other
##

def getMaxLevel(signal):
    return floor(log2(len(signal)))

def getAllWavelets():
    return ['haar','db2','db3','db4','db5','db6','db7','db8','db9','db10','db11','db12','db13','db14','db15','db16','db17','db18','db19','db20','sym2','sym3','sym4','sym5','sym6','sym7','sym8','sym9','sym10','sym11','sym12','sym13','sym14','sym15','sym16','sym17','sym18','sym19','sym20','coif1','coif2','coif3','coif4','coif5','meyer']